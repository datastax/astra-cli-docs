= astra db dsbulk unload

[source,shell]
----
astra db dsbulk unload [-qV] [--header] [--no-input] [--[no-]spinner] [--color
                       [=WHEN]] [--dump-logs[=FILE]] [--delimiter=DELIMITER]
                       [--dsbulk-config=CONFIG_FILE] [--encoding=ENCODING]
                       [-k=KEYSPACE] [--log-dir=DIRECTORY] [-m=MAPPING]
                       [--max-concurrent-queries=QUERIES] [--max-errors=COUNT]
                       [-o=FORMAT] [-query=QUERY] [-r=REGION]
                       [--skip-records=COUNT] [-t=TABLE] [--url=URL]
                       [-F=FLAGS]... [[[-cf=PATH] [-p=NAME]] | [--token=TOKEN
                       [--env=ENV]]] [DB]

----


Unload data leveraging DSBulk





== Options

`DB`:: The name or ID of the Astra database to operate on
`-k`, `--keyspace`:: Keyspace used for loading or unloading data
`-t`, `--table`:: Table used for loading or unloading data.
`--encoding`:: The file name format to use when writing. This setting is ignored when reading and for non-file URLs
`--max-concurrent-queries`:: The maximum number of concurrent queries that should be carried in parallel
`--log-dir`:: Log directory for dsbulk operations
`-r`, `--region`:: The region to use. Uses the db's default region if not specified.
`--dsbulk-config`:: Configuration file for DSBulk loader options
`-F`, `--dsbulk-flag`:: Additional flags to pass to DSBulk loader, can be specified multiple times (e.g., -F '--key1=value1' -F '--key2')
`--url`:: The URL or path of the resource(s) to read from or write to
`--delimiter`:: Character(s) use as field delimiter
`-m`, `--schema.mapping`:: Field-to-column mapping to use
`--header`:: Enable or disable whether the files begin with a header line
`--skip-records`:: Number of records to skip from each input file before parsing
`--max-errors`:: Maximum number of errors to tolerate before aborting the operation
`-query`, `--schema.query`:: Optional query to unload or count

.Common Options
[%collapsible]
====
`-o`, `--output`:: One of: human, json, csv
`-V`, `--verbose`:: Enable verbose logging output
`-q`, `--quiet`:: Only output essential information
`--spinner`:: Enable/disable loading spinners
`--no-input`:: Don't ask for user input (e.g. confirmation prompts)
`--color`:: One of: auto, never, always
`--dump-logs`:: Write all logs to an optionally specified file
====

.Connection Options
[%collapsible]
====
`-cf`, `--config-file`:: The ``.astrarc`` file to use for this command
`-p`, `--profile`:: The ``.astrarc`` profile to use for this command. Can be set via ``ASTRA_PROFILE``.
`--token`:: The astra token to use for this command. Use the ``--token @file`` syntax to read the token from a file, to avoid potential leaks.
`--env`:: Override the target astra environment
====


== Examples
[source,bash]
----
# Unload a table to a local directory
$ astra db dsbulk unload my_db -k my_keyspace -t customers --url dsbulk_out/customers --header

# Unload selected columns with renamed output headers
$ astra db dsbulk unload my_db -k my_keyspace -t products --url dsbulk_out/products_pipe --delimiter '|' -m 'product_sku=sku,product_name=name,usd_price=price' --header

# Unload only rows that match a query
$ astra db dsbulk unload my_db -k my_keyspace -query "SELECT * FROM orders_by_customer WHERE customer_id = 111111-1111-1111-1111-111111111111" --url dsbulk_out/orders_one_customer --header

# Unload a large table with custom output file naming and tuned paging
$ astra db dsbulk unload my_db -k my_keyspace -t orders_by_customer --url dsbulk_out/orders -F '--connector.csv.fileNameFormat=orders-%06d.csv' -F '--driver.basic.request.page-size=5000' --max-concurrent-queries 32 --header
----


